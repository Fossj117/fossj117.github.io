---
layout: page
title: Academic
permalink: /academic/
---

<html>
<style>
.paper-block {
  padding: 1.75rem 0;
  border-bottom: 1px solid rgba(128, 128, 128, 0.35);
}
.paper-block:last-of-type {
  border-bottom: none;
}
</style>

<section class="paper-block preamble">
<p>My academic research focuses on how we make collective decisions with and about emerging digital technologies. I am especially interested in the role of economic expertise in these decisions. Methodologically, I blend perspectives from statistics, economics, and science &amp; technology studies (STS).</p>
</section>

<section class="paper-block">
<h3><strong><em>Large Language Models for Bridging and Mediation in Online Conversations</em></strong></h3>
<p>This project is a collaboration with Ian Baker, Rose Bloomin, Peter Darche, Amina Green, Lisa Schirch, and Michael Luca. A preliminary draft is available upon request.</p>
<p><details>
<summary><em>Abstract</em></summary>

<!-- This study develops and experimentally tests an AI-based mediation tool designed to facilitate constructive online dialogue across political divides. Powered by a large language model (LLM), the tool automates mediation interventions grounded in communication and conflict resolution principles such as paraphrasing, identifying agreement, and encouraging perspective-taking. In a randomized controlled trial, the system successfully generated context-sensitive interventions in contentious conversations; however, effects on participants' attitudes towards people they disagree with were limited. The findings highlight both the promise and the challenges of using LLMs to promote healthier online discourse at scale.  -->

Forthcoming.

</details>
</p>
<p><details>
<summary><em>Media</em></summary>

<ul>
<li><a href="https://techandsocialcohesion.substack.com/p/from-battleground-to-common-ground">From battleground to common ground: Bridging Bot shows how AI designed to mediate could nudge toxic online spaces towards healthier discourse</a> – Council on Technology &amp; Social Cohesion.</li>
<li><a href="https://www.plurality.institute/blog-posts/exploring-opportunities-for-large-language-models-in-public-discourse">Exploring Opportunities for Large Language Models in Public Discourse</a> – Plurality Institute.</li>
<li><a href="https://www.youtube.com/watch?v=QgfXdJ-7pF4&amp;ab_channel=PluralityInstitute">Presentation</a> at ``LLMs in Public Discourse” conference.</li>
</ul>

</details>
</p>
</section>


<section class="paper-block">
<h3><strong><em>Leaving Money on the Dashboard: Price Dispersion and Search Frictions on Uber and Lyft</em></strong></h3>
<p>This project is a collaboration with Michael Luca and Yejia (Richard) Xu. A current draft is available <a href="https://www.nber.org/papers/w34441">on NBER</a>.</p>

<p><details>
<summary><em>Abstract</em></summary>

We document price differences for identical trips on Uber and Lyft, based on an audit of the two platforms. While price dispersion exists in the market, device-level data show that only 16.1 percent of consumers opening one app also open the other. Our estimates suggest that the modest frictions involved in comparison shopping increase platforms’ gross booking volume by over $300 million annually in New York City alone. While price-comparison engines could in principle reduce frictions, Uber’s API terms of use limit such services, reducing riders’ ability to price compare.

</details>
</p>

<p><details>
<summary><em>Media</em></summary>

<ul>
<li><a href="https://open.spotify.com/episode/4QKixrwtHtH5X8Sm3qUKwi?si=a685f46b94d84a62&nd=1&dlsi=6cf404da376c4683">50-year mortgages, falling real wages, and doing your rideshare due diligence</a> – The Indicator from Planet Money (NPR).</li>
</ul>

</details>
</p>
</section>

<section class="paper-block">
<h3><strong><em>Anticipating AI: How Worker Beliefs Shape Workforce Adaptation</em></strong></h3>
<p>This project is a collaboration with Michael Luca, Mingyang Sun, and Vijay Viswanathan. The project is currently in the data collection phase.</p>

<p><details>
<summary><em>Abstract</em></summary>

As generative artificial intelligence (AI) tools such as large language models (LLMs) grow increasingly capable, workers face uncertainty about if and how these technologies will reshape their jobs. While economists have documented that a wide range of occupations may be exposed to AI, much less is known about how workers themselves perceive these changes, and how their beliefs shape their present-day economic behaviors. Beliefs about the future matter: workers’ expectations about AI’s development, governance, and adoption may drive decisions about retraining, education, or career shifts, regardless of whether these expectations diverge from expert forecasts. In this paper, we design and conduct a survey and randomized experiment to study the role of worker beliefs in shaping labor market responses to generative AI, with a focus on two professional fields: law and management consulting. We first examine the content and distribution of workers’ beliefs about AI’s future impact on their own and adjacent professions, and then test whether these beliefs are correlated with adaptive behaviors such as learning about AI tools, investing in training, or considering new careers. Finally, we leverage experimental variation to examine how worker beliefs, decisions, and policy preferences are affected by exposure to diverging arguments from economic experts about the likely impacts of AI in the labor market.

</details>
</p>
</section>


<section class="paper-block">
<h3><strong><em>Perfomativity, Complexity & Framing in the FCC Incentive Auction</em></strong></h3>
<p>This project is a work in progress. It was presented at Harvard's <a href="https://www.wcfia.harvard.edu/event/science-technology-and-society-seminar-sts-circle-02-24-25">STS Circle</a> and <a href="https://sts.hks.harvard.edu/events/workshops/grists-2024/">GRiSTS</a> in 2024. An extended abstract is available <a href="/files/Fossett_GRiSTS_Summary.pdf">here</a>.</p>

<p><details>
<summary><em>Abstract</em></summary>

<p> In this paper, I study the Federal Communication Commission’s 2016 Spectrum Incentive Auction, which was developed in collaboration with academic market design economists to reallocate spectrum broadcasting rights from local cable television broadcasters to mobile broadband providers. The paper will proceed in three parts. First, I will analyze the Incentive Auction from the perspective of the performativity of economics (e.g. Mitchell 2007; MacKenzie 2008), focusing especially on the work of ``framing” (Callon 1998)--that is, the work of delineating the economic objects, agents, and decisions that would be ``on stage” and hence relevant in auction transactions. I will show that none of this framing was accomplished ``for free”, but instead required various background legal, political, and material investments to hold in place. Second, I will zoom out and examine the design flexibility of the auction as whole. Of the many ways that the public problem of spectrum reallocation might have been addressed , how and why was the Incentive Auction understood as a necessary, appropriate, and ultimately successful solution? In addressing this question, I will focus especially on the role of ``complexity” in rendering the auction, its particular form, and expert intervention more broadly, as necessary. I will argue that rendering the problem ``complex” is a co-productive move (Jasanoff 2004): it involves both (1) making a fact about the economic reality, and (2) drawing a normative implication about the need for particular sorts of economic expertise in helping to manage it. In the third and final part of the paper, I will consider the auction’s success, exploring how it was rendered successful despite evidence of overflowing (Callon 1998) in the form of strategic manipulation by private equity firms and multi-station owners (Doraszelski et al. 2017). </p>

</details>
</p>
</section>

<section class="paper-block">
<h3><strong><em>Resale Royalties in Digital Art Markets</em></strong></h3>

This project is in progress. First phase data collection and analysis are complete.


<p><details>
<summary><em>Abstract</em></summary>

<p> Resale royalty policies (<em>droit de suite</em> or ``right to follow”) entitle artists to a percentage of secondary market sales of their artwork. These policies have been implemented in many offline art markets (including the UK, EU, and parts of the US) and have been subject to much theoretical debate in economics, law, and policy. At the same time, these policies have recently become popular in digital art markets based on the blockchain, where they are enforced by marketplace platforms rather than governments. Despite their popularity, there is limited high-quality empirical evidence about the consequences of resale royalty policies, partially due to data limitations in offline art markets, such as the inability to observe private sales which represent over half of transactions. In this project I use data from blockchain-based non-fungible token (NFT) art markets to study the effect of resale royalty policies; in particular, I examine the effect of these policies on prices and quantities in the secondary market for NFT assets. To identify causal effects, I take advantage of a recent series of marketplace platform policy changes - driven by competition for buyers - which have substantially reduced effective royalty enforcement in the Ethereum NFT space. </p>

</details>
</p>
</section>
</html>